{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63de82b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igorg\\Documents\\Programação\\PDSI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "from transformers import CLIPTextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47dbb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"C:\\\\Users\\\\igorg\\\\Documents\\\\Programação\\\\PDSI\\\\imagens\\\\kkk.jpeg\"\n",
    "\n",
    "LORA_FOLDER = \"C:\\\\Users\\\\igorg\\\\Documents\\\\Programação\\\\PDSI\\\\output\\\\cyberpunk_style\"\n",
    "\n",
    "BASE_MODEL_ID = \"stablediffusionapi/anything-v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7737c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIGGER_WORD = \"cyberpunk_art\"  # ou a palavra certa do seu LoRA\n",
    "\n",
    "PROMPT = f\"{TRIGGER_WORD}, cyborg sleeping, system recharge mode, wires connected to head, futuristic techwear armor, glowing blue neon lights, dark sci-fi lab background, low battery warning, high tech, cyberpunk 2077 vibes, masterpiece\"\n",
    "\n",
    "NEGATIVE_PROMPT = \"daylight, sun, natural background, rustic, vintage, awake, alert eyes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01a8d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"./resultados_style_CB\"\n",
    "SEED = 42\n",
    "NUM_STEPS = 30\n",
    "GUIDANCE_SCALE = 7.5\n",
    "STRENGTH = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c17fc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando com GPU: NVIDIA GeForce RTX 3050 Laptop GPU ---\n",
      "Carregando modelo base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at stablediffusionapi/anything-v5 were not used when initializing CLIPTextModel: ['text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.11.self_attn.v_proj.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 10 checkpoints.\n",
      "--> Testando: cyberpunk_style-01.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:11<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-01.png\n",
      "--> Testando: cyberpunk_style-02.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:09<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-02.png\n",
      "--> Testando: cyberpunk_style-03.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:09<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-03.png\n",
      "--> Testando: cyberpunk_style-04.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:09<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-04.png\n",
      "--> Testando: cyberpunk_style-05.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:10<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-05.png\n",
      "--> Testando: cyberpunk_style-06.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:10<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-06.png\n",
      "--> Testando: cyberpunk_style-07.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:10<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-07.png\n",
      "--> Testando: cyberpunk_style-08.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:10<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-08.png\n",
      "--> Testando: cyberpunk_style-09.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:09<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-09.png\n",
      "--> Testando: cyberpunk_style-10.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 22/22 [00:09<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_cyberpunk_style-10.png\n",
      "\n",
      "SUCESSO! Verifique a pasta 'resultados_finais'.\n"
     ]
    }
   ],
   "source": [
    "def run_style_transfer():\n",
    "    print(f\"--- Iniciando com GPU: {torch.cuda.get_device_name(0)} ---\")\n",
    "    \n",
    "    # 1. Carregar Modelo Base\n",
    "    print(f\"Carregando modelo base...\")\n",
    "    \n",
    "    # Clip Skip 2\n",
    "    text_encoder = CLIPTextModel.from_pretrained(\n",
    "        BASE_MODEL_ID, \n",
    "        subfolder=\"text_encoder\", \n",
    "        num_hidden_layers=11\n",
    "    )\n",
    "\n",
    "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        BASE_MODEL_ID,\n",
    "        text_encoder=text_encoder,\n",
    "        torch_dtype=torch.float16, \n",
    "        safety_checker=None\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Otimizações de memória para a RTX 3050\n",
    "    pipe.enable_attention_slicing()\n",
    "    pipe.enable_model_cpu_offload() # <--- ESSA É A MÁGICA PARA 4GB/6GB VRAM\n",
    "\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "    # 2. Carregar Imagem\n",
    "    if not os.path.exists(INPUT_IMAGE_PATH):\n",
    "        print(f\"ERRO: A imagem '{INPUT_IMAGE_PATH}' não existe na pasta!\")\n",
    "        return\n",
    "\n",
    "    init_image = load_image(INPUT_IMAGE_PATH).resize((512, 512))\n",
    "\n",
    "    lora_files = sorted([f for f in os.listdir(LORA_FOLDER) if f.endswith(\".safetensors\")])\n",
    "    print(f\"Encontrados {len(lora_files)} checkpoints.\")\n",
    "\n",
    "    for lora_file in lora_files:\n",
    "        lora_path = os.path.join(LORA_FOLDER, lora_file)\n",
    "        print(f\"--> Testando: {lora_file}\")\n",
    "\n",
    "        try:\n",
    "            pipe.load_lora_weights(lora_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar LoRA: {e}\")\n",
    "            continue\n",
    "\n",
    "        generator = torch.Generator(device=\"cuda\").manual_seed(SEED)\n",
    "        \n",
    "        # --- A CORREÇÃO ESTÁ AQUI: AUTOCAST ---\n",
    "        # Isso converte automaticamente os tipos float32/float16 na hora certa\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            result = pipe(\n",
    "                prompt=PROMPT,\n",
    "                image=init_image,\n",
    "                strength=STRENGTH,\n",
    "                negative_prompt=NEGATIVE_PROMPT,\n",
    "                num_inference_steps=28,\n",
    "                guidance_scale=GUIDANCE_SCALE,\n",
    "                generator=generator\n",
    "            ).images[0]\n",
    "        # --------------------------------------\n",
    "\n",
    "        save_name = f\"teste_{lora_file.replace('.safetensors', '')}.png\"\n",
    "        result.save(os.path.join(OUTPUT_FOLDER, save_name))\n",
    "        print(f\"Salvo: {save_name}\")\n",
    "\n",
    "        pipe.unload_lora_weights()\n",
    "\n",
    "    print(\"\\nSUCESSO! Verifique a pasta 'resultados_finais'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_style_transfer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
