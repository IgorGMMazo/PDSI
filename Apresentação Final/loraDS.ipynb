{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "606338c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q diffusers transformers accelerate safetensors scipy\n",
    "%pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bba93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip -q install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab600f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igorg\\Documents\\Programação\\PDSI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "from transformers import CLIPTextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a978a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"C:\\\\Users\\\\igorg\\\\Documents\\\\Programação\\\\PDSI\\\\imagens\\\\kkk.jpeg\"\n",
    "\n",
    "LORA_FOLDER = \"C:\\\\Users\\\\igorg\\\\Documents\\\\Programação\\\\PDSI\\\\output\\\\demon_slayer_style\"\n",
    "\n",
    "BASE_MODEL_ID = \"stablediffusionapi/anything-v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3643a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIGGER_WORD = \"demon_slayer_art\"  # ou a palavra certa do seu LoRA\n",
    "\n",
    "PROMPT = f\"{TRIGGER_WORD}, 1boy, sleeping, passed out, eyes closed, drooling bubble (comic effect), demon slayer uniform, blue haori, exhausted, funny anime expression, sitting on a wooden bench, dojo background, anime style, ufotable style, cel shaded, masterpiece\"\n",
    "\n",
    "NEGATIVE_PROMPT = \"realistic, photo, 3d, open eyes, awake, standing, bad anatomy, blurry, low quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7931bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"./resultados_style_DS\"\n",
    "SEED = 42\n",
    "NUM_STEPS = 30\n",
    "GUIDANCE_SCALE = 7.5\n",
    "STRENGTH = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e69f409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando com GPU: NVIDIA GeForce RTX 3050 Laptop GPU ---\n",
      "Carregando modelo base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at stablediffusionapi/anything-v5 were not used when initializing CLIPTextModel: ['text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.11.self_attn.v_proj.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 7 checkpoints.\n",
      "--> Testando: demon_slayer_style-01.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 18/18 [00:09<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_demon_slayer_style-01.png\n",
      "--> Testando: demon_slayer_style-02.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 18/18 [00:09<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_demon_slayer_style-02.png\n",
      "--> Testando: demon_slayer_style-03.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_demon_slayer_style-03.png\n",
      "--> Testando: demon_slayer_style-04.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_demon_slayer_style-04.png\n",
      "--> Testando: demon_slayer_style-05.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 18/18 [00:08<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_demon_slayer_style-05.png\n",
      "--> Testando: demon_slayer_style-06.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_demon_slayer_style-06.png\n",
      "--> Testando: demon_slayer_style-07.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from state_dict led to unexpected keys not found in the model: text_model.encoder.layers.11.mlp.fc1.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc1.lora_B.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_A.default_0.weight, text_model.encoder.layers.11.mlp.fc2.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.k_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.out_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.q_proj.lora_B.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_A.default_0.weight, text_model.encoder.layers.11.self_attn.v_proj.lora_B.default_0.weight. \n",
      "100%|██████████| 18/18 [00:08<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: teste_demon_slayer_style-07.png\n",
      "\n",
      "SUCESSO! Verifique a pasta 'resultados_finais'.\n"
     ]
    }
   ],
   "source": [
    "def run_style_transfer():\n",
    "    print(f\"--- Iniciando com GPU: {torch.cuda.get_device_name(0)} ---\")\n",
    "    \n",
    "    # 1. Carregar Modelo Base\n",
    "    print(f\"Carregando modelo base...\")\n",
    "    \n",
    "    # Clip Skip 2\n",
    "    text_encoder = CLIPTextModel.from_pretrained(\n",
    "        BASE_MODEL_ID, \n",
    "        subfolder=\"text_encoder\", \n",
    "        num_hidden_layers=11\n",
    "    )\n",
    "\n",
    "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        BASE_MODEL_ID,\n",
    "        text_encoder=text_encoder,\n",
    "        torch_dtype=torch.float16, \n",
    "        safety_checker=None\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Otimizações de memória para a RTX 3050\n",
    "    pipe.enable_attention_slicing()\n",
    "    pipe.enable_model_cpu_offload() # <--- ESSA É A MÁGICA PARA 4GB/6GB VRAM\n",
    "\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "    # 2. Carregar Imagem\n",
    "    if not os.path.exists(INPUT_IMAGE_PATH):\n",
    "        print(f\"ERRO: A imagem '{INPUT_IMAGE_PATH}' não existe na pasta!\")\n",
    "        return\n",
    "\n",
    "    init_image = load_image(INPUT_IMAGE_PATH).resize((512, 512))\n",
    "\n",
    "    lora_files = sorted([f for f in os.listdir(LORA_FOLDER) if f.endswith(\".safetensors\")])\n",
    "    print(f\"Encontrados {len(lora_files)} checkpoints.\")\n",
    "\n",
    "    for lora_file in lora_files:\n",
    "        lora_path = os.path.join(LORA_FOLDER, lora_file)\n",
    "        print(f\"--> Testando: {lora_file}\")\n",
    "\n",
    "        try:\n",
    "            pipe.load_lora_weights(lora_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar LoRA: {e}\")\n",
    "            continue\n",
    "\n",
    "        generator = torch.Generator(device=\"cuda\").manual_seed(SEED)\n",
    "        \n",
    "        # --- A CORREÇÃO ESTÁ AQUI: AUTOCAST ---\n",
    "        # Isso converte automaticamente os tipos float32/float16 na hora certa\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            result = pipe(\n",
    "                prompt=PROMPT,\n",
    "                image=init_image,\n",
    "                strength=STRENGTH,\n",
    "                negative_prompt=NEGATIVE_PROMPT,\n",
    "                num_inference_steps=28,\n",
    "                guidance_scale=GUIDANCE_SCALE,\n",
    "                generator=generator\n",
    "            ).images[0]\n",
    "        # --------------------------------------\n",
    "\n",
    "        save_name = f\"teste_{lora_file.replace('.safetensors', '')}.png\"\n",
    "        result.save(os.path.join(OUTPUT_FOLDER, save_name))\n",
    "        print(f\"Salvo: {save_name}\")\n",
    "\n",
    "        pipe.unload_lora_weights()\n",
    "\n",
    "    print(\"\\nSUCESSO! Verifique a pasta 'resultados_finais'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_style_transfer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
